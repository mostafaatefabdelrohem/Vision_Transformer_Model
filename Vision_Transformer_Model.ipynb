{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUu_klp3IIUa",
        "outputId": "8c47f00a-5028-4590-c385-946acadde7f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "TensorFlow Version 2.12.0\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
        "\n",
        "!pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "!pip install --quiet vit-keras\n",
        "import tensorflow_addons as tfa\n",
        "from vit_keras import vit\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "import pandas as pd\n",
        "import tensorflow_addons as tfa\n",
        "import glob, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print('TensorFlow Version ' + tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q66c5t4PEYO",
        "outputId": "cd596c8d-94b8-49c6-8f02-048774dc495b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRq6xi5wRdLx",
        "outputId": "67148292-a4c4-4745-c46f-1e64e8104aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 7: Preprocessing the Data\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   preprocessing_function = preprocess_input)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  preprocessing_function = preprocess_input)\n",
        "\n",
        "# Step 8: Load the Data\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/face_emotions/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 128,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/face_emotions/test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 128,\n",
        "                                            class_mode = 'categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgPTkFiiw29F"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Image size\n",
        "\n",
        "IMAGE_SIZE = (224,224)\n",
        "IMAGE_SHAPE = IMAGE_SIZE + (3,)\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "ADAM_LEARNING_RATE = 0.0001\n",
        "PATIENCE =10\n",
        "classes=['Angry','Disgust','Fear','Happy','Neutral','Sad','Surprise']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3lIWhV-wwtd",
        "outputId": "29550aa0-d43d-462f-e216-dbc7ea322ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vision_transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vit-b32 (Functional)        (None, 768)               87455232  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 768)               0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 768)              3072      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               98432     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,558,151\n",
            "Trainable params: 87,556,359\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vit_model = vit.vit_b32(\n",
        "        image_size = IMAGE_SIZE,\n",
        "        activation = 'softmax',\n",
        "        pretrained = True,\n",
        "        include_top = False,\n",
        "        pretrained_top = False,\n",
        "        classes = 7)\n",
        "model = tf.keras.Sequential([\n",
        "        vit_model,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(128, activation = tfa.activations.gelu),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(7, 'softmax')\n",
        "    ],\n",
        "    name = 'vision_transformer')\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ66mpuqyIFv"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-4\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
        "\n",
        "METRICS = ['accuracy']\n",
        "model.compile(optimizer = optimizer,\n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2),\n",
        "              metrics = METRICS)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoQqOOXr0PeH",
        "outputId": "a4b722e3-d0c5-431a-8ea8-8931a512684d"
      },
      "outputs": [],
      "source": [
        "model.fit(x = training_set,\n",
        "          validation_data =test_set,\n",
        "          epochs = EPOCHS,\n",
        "          )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvKKMfDkTxGt"
      },
      "outputs": [],
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"ViT_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"ViT_model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "from google.colab import files\n",
        "files.download('ViT_model.h5')\n",
        "files.download('ViT_model.json')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
